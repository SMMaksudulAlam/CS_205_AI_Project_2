{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "c2fNDL58oO0B"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def means(features):\n",
        "    num_columns = len(features[0])\n",
        "    means = [sum(col) / len(col) for col in zip(*features)]\n",
        "    return means"
      ],
      "metadata": {
        "id": "oMQW1jfHoVbw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stds(features, means_):\n",
        "    num_columns = len(features[0])\n",
        "    stds_ = []\n",
        "    num_rows = len(features)\n",
        "    for i in range(num_columns):\n",
        "        sum_squared_diff = 0\n",
        "        for j in range(num_rows):\n",
        "            squared_diff = (features[j][i] - means_[i]) ** 2\n",
        "            sum_squared_diff += squared_diff\n",
        "        column_std = math.sqrt(sum_squared_diff / (num_rows- 1))\n",
        "        stds_.append(column_std)\n",
        "    return stds_"
      ],
      "metadata": {
        "id": "Tr-NIyoSoXaA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(features):\n",
        "    means_ = means(features)\n",
        "    stds_ = stds(features, means_)\n",
        "    num_columns = len(features[0])\n",
        "    num_rows = len(features)\n",
        "    for i in range(num_rows):\n",
        "        for j in range(num_columns):\n",
        "            features[i][j] = (features[i][j] - means_[j]) / stds_[j]\n",
        "    return features"
      ],
      "metadata": {
        "id": "P1qn4VFFobUD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_distance(sample1, sample2, feats):\n",
        "    e_dist = 0\n",
        "    for f in feats:\n",
        "        e_dist += math.pow((sample1[f] - sample2[f]), 2)\n",
        "    return math.sqrt(e_dist)"
      ],
      "metadata": {
        "id": "RmLBbgM2oeQn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nearest_N(train, test, feats):\n",
        "    distances = []\n",
        "    for sample_t in train:\n",
        "        e_dist = euclidean_distance(sample_t, test, feats)\n",
        "        distances.append([e_dist, sample_t[0]])\n",
        "    distances = sorted(distances, key=lambda x: x[0])\n",
        "    return distances[0][1]"
      ],
      "metadata": {
        "id": "DdExg1s9ofNO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(dataset, features, k):\n",
        "    count = 0\n",
        "    total = 0\n",
        "    curr_feats = features[:]\n",
        "    n = len(dataset)//k\n",
        "    for i in range(k):\n",
        "        test = dataset[i*n:(i+1)*n]\n",
        "        train = dataset[:i*n] + dataset[(i+1)*n:]\n",
        "        for t in (test):\n",
        "            cls = nearest_N(train, t, curr_feats)\n",
        "            total += 1\n",
        "            if (cls == t[0]):\n",
        "                count += 1\n",
        "    acc = float(count) / total\n",
        "    return acc"
      ],
      "metadata": {
        "id": "aNJSXyfnohcH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_selection(dataset, selected_features, final_features, final_acc, k):\n",
        "    if(len(selected_features) == len(dataset[0]) - 1):\n",
        "        return final_features, final_acc\n",
        "    num_features = len(dataset[0])\n",
        "    selected_features = selected_features[:]\n",
        "    acc = 0\n",
        "    current_features = []\n",
        "    print('selected features:', selected_features)\n",
        "    print('finalized features:', final_features)\n",
        "    print('final accuracy:', round(final_acc*100, 1),'%')\n",
        "    for n in range(1, num_features):\n",
        "        prev_features = selected_features[:]\n",
        "        if n not in selected_features:\n",
        "            prev_features.append(n)\n",
        "            acc = accuracy(dataset, prev_features, k)\n",
        "            temp = []\n",
        "            temp.append(acc)\n",
        "            temp.append(n)\n",
        "            current_features.append(temp)\n",
        "            print('for feature', n,'=> the accuracy is:', round(acc*100, 1),'%')\n",
        "    current_features = sorted(current_features, key=lambda x: x[0], reverse=True)\n",
        "    #print(current_features[0][1])\n",
        "    selected_features.append(current_features[0][1])\n",
        "    acc = current_features[0][0]\n",
        "    if(acc>final_acc):\n",
        "        final_features.append(current_features[0][1])\n",
        "        final_acc = acc\n",
        "    #print(selected_features, final_features, final_acc)\n",
        "    return forward_selection(dataset, selected_features, final_features, final_acc, k)"
      ],
      "metadata": {
        "id": "K3ID4DPuBbPu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_elimination(dataset, selected_features, final_features, final_acc, k):\n",
        "    if(len(selected_features) == 0):\n",
        "        return final_features, final_acc\n",
        "    num_features = len(dataset[0])\n",
        "    selected_features = selected_features[:]\n",
        "    acc = 0\n",
        "    current_features = []\n",
        "    print('selected features:', selected_features)\n",
        "    print('finalized features:', final_features)\n",
        "    print('final accuracy:', round(final_acc*100, 1),'%')\n",
        "    for n in range(1, num_features):\n",
        "        prev_features = selected_features[:]\n",
        "        if n in selected_features:\n",
        "            prev_features.remove(n)\n",
        "            acc = accuracy(dataset, prev_features, k)\n",
        "            temp = []\n",
        "            temp.append(acc)\n",
        "            temp.append(n)\n",
        "            current_features.append(temp)\n",
        "            print('for feature', n,'=> the accuracy is:', round(acc*100, 1),'%')\n",
        "    current_features = sorted(current_features, key=lambda x: x[0], reverse=True)\n",
        "    #print(current_features[0][1])\n",
        "    selected_features.remove(current_features[0][1])\n",
        "    acc = current_features[0][0]\n",
        "    if(acc>final_acc):\n",
        "        final_features.remove(current_features[0][1])\n",
        "        final_acc = acc\n",
        "    #print(selected_features, final_features, final_acc)\n",
        "    return backward_elimination(dataset, selected_features, final_features, final_acc, k)"
      ],
      "metadata": {
        "id": "LRshTcWuCDPh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    print(\"Wecome to the feature selector platform.\\n\")\n",
        "    print(\"\\nYou can choose any of two types of dataset:\")\n",
        "    print(\"1. Small dataset in data_sets folder.\")\n",
        "    print(\"2. Large dataset in data_sets folder.\")\n",
        "    print(\"3. Extra large dataset in data_sets folder.\")\n",
        "    print(\"4. A real life dataset: glass.data.\")\n",
        "    dataset_type = input('Please enter the correspoinding number for the dataset type: ')\n",
        "\n",
        "    data_path = ''\n",
        "    if(dataset_type == '1'):\n",
        "      data_path = '/content/data_sets/CS170_small_Data__12.txt'   \n",
        "    if(dataset_type == '2'):\n",
        "      data_path = '/content/data_sets/CS170_large_Data__11.txt'  \n",
        "    if(dataset_type == '3'):\n",
        "      data_path = '/content/data_sets/CS170_XXXlarge_Data__21.txt'   \n",
        "    if(dataset_type == '4'):\n",
        "      data_path = '/content/glass.data'           \n",
        "    \n",
        "\n",
        "    dataset = None\n",
        "    if(dataset_type != '4'):\n",
        "        print(\"\\nloading data...\\n\")\n",
        "        with open(data_path, 'r') as file:\n",
        "            rows = file.readlines()\n",
        "        classes = []\n",
        "        features = []\n",
        "        for row in rows:\n",
        "            data = row.strip().split()\n",
        "            cls = float(data.pop(0))\n",
        "            classes.append(cls)\n",
        "            feature = [float(ftr) for ftr in data[:]]\n",
        "            features.append(feature)\n",
        "        print(\"normalizing data...\\n\")\n",
        "        features = normalize(features)\n",
        "\n",
        "        dataset = np.array(features)\n",
        "        dataset = np.insert(dataset, 0, classes, axis=1).tolist()\n",
        "    else:\n",
        "        print('loading data...')\n",
        "        with open(data_path, 'r') as file:\n",
        "            rows = file.read().split('\\n')\n",
        "        rows = rows[:len(rows)-1]\n",
        "        classes = []\n",
        "        features = []\n",
        "        print(len(rows))\n",
        "        for row in rows:\n",
        "            data = row.strip().split(',')\n",
        "            cls = float(data.pop())\n",
        "            classes.append(cls)\n",
        "            feature = [float(ftr) for ftr in data[:]]\n",
        "            feature = feature[1:]\n",
        "            features.append(feature)\n",
        "\n",
        "        print(\"normalizing data...\\n\")\n",
        "        features = normalize(features)\n",
        "\n",
        "        dataset = np.array(features)\n",
        "        dataset = np.insert(dataset, 0, classes, axis=1).tolist()\n",
        "                         \n",
        "    print(\"\\nYou can choose one of the following algorithms:\")\n",
        "    print(\"1. Forward selection.\")\n",
        "    print(\"2. Backward elimination.\")\n",
        "    algo = input(\"Please enter the correspoinding number for the chosen algorithm: \")\n",
        "    \n",
        "    final_features = None\n",
        "    final_acc = 0\n",
        "    if(algo == '1'):\n",
        "        print(\"starting the forward selection approach...\")\n",
        "        if(dataset_type == '3'):\n",
        "          final_features, final_acc = forward_selection(dataset, [], [], 0, 2)\n",
        "        else:\n",
        "          final_features, final_acc = forward_selection(dataset, [], [], 0, len(dataset))\n",
        "        print('\\n\\nfinally, the finalized features and accuracy are:')\n",
        "        print(final_features, round(final_acc*100, 1),'%')\n",
        "        print(\"forward selection approach ended!\\n\\n\")\n",
        "    if(algo == '2'):\n",
        "        print(\"starting the backward elimination approach...\")\n",
        "        initial_features = [i for i in range(1, len(dataset[0]))]\n",
        "        inital_final_features = initial_features[:]\n",
        "        if(dataset_type == '3'):\n",
        "          acc = accuracy(dataset, initial_features, 2)\n",
        "          final_features, final_acc = backward_elimination(dataset, initial_features, inital_final_features, acc, 2)\n",
        "        else:\n",
        "          acc = accuracy(dataset, initial_features, len(dataset))\n",
        "          final_features, final_acc = backward_elimination(dataset, initial_features, inital_final_features, acc, len(dataset))\n",
        "        print()\n",
        "        print()\n",
        "        print('finally, the finalized features and accuracy are:')\n",
        "        print(final_features, round(final_acc*100, 1),'%')\n",
        "        print(\"backward elimination approach ended!\\n\\n\")"
      ],
      "metadata": {
        "id": "tEgoJq7QKy1w"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__==\"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "g3HrPgLAO6O1",
        "outputId": "2af507e5-ab89-45c3-a2a8-18c6efed9dd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wecome to the feature selector platform.\n",
            "\n",
            "\n",
            "You can choose any of two types of dataset:\n",
            "1. Small dataset in data_sets folder.\n",
            "2. Large dataset in data_sets folder.\n",
            "3. Extra large dataset in data_sets folder.\n",
            "4. A real life dataset: glass.data.\n",
            "Please enter the correspoinding number for the dataset type: 1\n",
            "\n",
            "loading data...\n",
            "\n",
            "normalizing data...\n",
            "\n",
            "\n",
            "You can choose one of the following algorithms:\n",
            "1. Forward selection.\n",
            "2. Backward elimination.\n",
            "Please enter the correspoinding number for the chosen algorithm: 1\n",
            "starting the forward selection approach...\n",
            "selected features: []\n",
            "finalized features: []\n",
            "final accuracy: 0 %\n",
            "for feature 1 => the accuracy is: 83.4 %\n",
            "for feature 2 => the accuracy is: 69.4 %\n",
            "for feature 3 => the accuracy is: 69.8 %\n",
            "for feature 4 => the accuracy is: 69.6 %\n",
            "for feature 5 => the accuracy is: 67.2 %\n",
            "for feature 6 => the accuracy is: 71.8 %\n",
            "for feature 7 => the accuracy is: 66.5 %\n",
            "for feature 8 => the accuracy is: 65.2 %\n",
            "for feature 9 => the accuracy is: 67.6 %\n",
            "for feature 10 => the accuracy is: 70.5 %\n",
            "selected features: [1]\n",
            "finalized features: [1]\n",
            "final accuracy: 83.4 %\n",
            "for feature 2 => the accuracy is: 84.5 %\n",
            "for feature 3 => the accuracy is: 83.5 %\n",
            "for feature 4 => the accuracy is: 85.1 %\n",
            "for feature 5 => the accuracy is: 81.4 %\n",
            "for feature 6 => the accuracy is: 95.9 %\n",
            "for feature 7 => the accuracy is: 83.1 %\n",
            "for feature 8 => the accuracy is: 82.1 %\n",
            "for feature 9 => the accuracy is: 84.9 %\n",
            "for feature 10 => the accuracy is: 83.0 %\n",
            "selected features: [1, 6]\n",
            "finalized features: [1, 6]\n",
            "final accuracy: 95.9 %\n",
            "for feature 2 => the accuracy is: 92.0 %\n",
            "for feature 3 => the accuracy is: 91.2 %\n",
            "for feature 4 => the accuracy is: 95.4 %\n",
            "for feature 5 => the accuracy is: 91.3 %\n",
            "for feature 7 => the accuracy is: 93.9 %\n",
            "for feature 8 => the accuracy is: 91.8 %\n",
            "for feature 9 => the accuracy is: 92.4 %\n",
            "for feature 10 => the accuracy is: 92.2 %\n",
            "selected features: [1, 6, 4]\n",
            "finalized features: [1, 6]\n",
            "final accuracy: 95.9 %\n",
            "for feature 2 => the accuracy is: 89.3 %\n",
            "for feature 3 => the accuracy is: 89.8 %\n",
            "for feature 5 => the accuracy is: 89.4 %\n",
            "for feature 7 => the accuracy is: 90.8 %\n",
            "for feature 8 => the accuracy is: 89.7 %\n",
            "for feature 9 => the accuracy is: 90.7 %\n",
            "for feature 10 => the accuracy is: 90.8 %\n",
            "selected features: [1, 6, 4, 7]\n",
            "finalized features: [1, 6]\n",
            "final accuracy: 95.9 %\n",
            "for feature 2 => the accuracy is: 85.2 %\n",
            "for feature 3 => the accuracy is: 86.4 %\n",
            "for feature 5 => the accuracy is: 86.8 %\n",
            "for feature 8 => the accuracy is: 86.5 %\n",
            "for feature 9 => the accuracy is: 86.7 %\n",
            "for feature 10 => the accuracy is: 86.9 %\n",
            "selected features: [1, 6, 4, 7, 10]\n",
            "finalized features: [1, 6]\n",
            "final accuracy: 95.9 %\n",
            "for feature 2 => the accuracy is: 83.1 %\n",
            "for feature 3 => the accuracy is: 83.8 %\n",
            "for feature 5 => the accuracy is: 85.1 %\n",
            "for feature 8 => the accuracy is: 84.3 %\n",
            "for feature 9 => the accuracy is: 84.9 %\n",
            "selected features: [1, 6, 4, 7, 10, 5]\n",
            "finalized features: [1, 6]\n",
            "final accuracy: 95.9 %\n",
            "for feature 2 => the accuracy is: 79.6 %\n",
            "for feature 3 => the accuracy is: 82.0 %\n",
            "for feature 8 => the accuracy is: 82.9 %\n",
            "for feature 9 => the accuracy is: 80.2 %\n",
            "selected features: [1, 6, 4, 7, 10, 5, 8]\n",
            "finalized features: [1, 6]\n",
            "final accuracy: 95.9 %\n",
            "for feature 2 => the accuracy is: 79.3 %\n",
            "for feature 3 => the accuracy is: 79.0 %\n",
            "for feature 9 => the accuracy is: 78.4 %\n",
            "selected features: [1, 6, 4, 7, 10, 5, 8, 2]\n",
            "finalized features: [1, 6]\n",
            "final accuracy: 95.9 %\n",
            "for feature 3 => the accuracy is: 75.2 %\n",
            "for feature 9 => the accuracy is: 77.0 %\n",
            "selected features: [1, 6, 4, 7, 10, 5, 8, 2, 9]\n",
            "finalized features: [1, 6]\n",
            "final accuracy: 95.9 %\n",
            "for feature 3 => the accuracy is: 75.0 %\n",
            "\n",
            "\n",
            "finally, the finalized features and accuracy are:\n",
            "[1, 6] 95.9 %\n",
            "forward selection approach ended!\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__==\"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "0A79nGiuRLtK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}